{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14132265,"sourceType":"datasetVersion","datasetId":9005128}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport warnings\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:50:25.338420Z","iopub.execute_input":"2025-12-14T21:50:25.339090Z","iopub.status.idle":"2025-12-14T21:50:32.835440Z","shell.execute_reply.started":"2025-12-14T21:50:25.339067Z","shell.execute_reply":"2025-12-14T21:50:32.834653Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load datasets\n\ntrain = pd.read_csv('/kaggle/input/flight-delay-prediction/Train.csv')\ntest = pd.read_csv('/kaggle/input/flight-delay-prediction/Test.csv')\n\nprint(f\"Train shape: {train.shape}\")\nprint(f\"Test shape: {test.shape}\")\ntrain.head()\ntrain['target'].describe()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:50:35.167408Z","iopub.execute_input":"2025-12-14T21:50:35.168355Z","iopub.status.idle":"2025-12-14T21:50:35.461529Z","shell.execute_reply.started":"2025-12-14T21:50:35.168330Z","shell.execute_reply":"2025-12-14T21:50:35.460928Z"}},"outputs":[{"name":"stdout","text":"Train shape: (107833, 10)\nTest shape: (9333, 9)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"count    107833.000000\nmean         48.733013\nstd         117.135562\nmin           0.000000\n25%           0.000000\n50%          14.000000\n75%          43.000000\nmax        3451.000000\nName: target, dtype: float64"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Separate features and target\nX = train.drop(['target', 'id'], axis=1, errors='ignore')\ny = train['target']\nX_test = test.drop(['id'], axis=1, errors='ignore')\n\n# Identify column types\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n\nprint(f\"\\ Colonnes numériques: {len(numeric_cols)}\")\nprint(f\"  {numeric_cols}\")\nprint(f\"\\ Colonnes catégorielles: {len(categorical_cols)}\")\nprint(f\"  {categorical_cols}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:50:37.920194Z","iopub.execute_input":"2025-12-14T21:50:37.920479Z","iopub.status.idle":"2025-12-14T21:50:37.955039Z","shell.execute_reply.started":"2025-12-14T21:50:37.920456Z","shell.execute_reply":"2025-12-14T21:50:37.954396Z"}},"outputs":[{"name":"stdout","text":"\\ Colonnes numériques: 0\n  []\n\\ Colonnes catégorielles: 9\n  ['ID', 'DATOP', 'FLTID', 'DEPSTN', 'ARRSTN', 'STD', 'STA', 'STATUS', 'AC']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Handle missing values for numeric columns\nfor col in numeric_cols:\n    if X[col].isnull().sum() > 0:\n        median_val = X[col].median()\n        X[col].fillna(median_val, inplace=True)\n        X_test[col].fillna(median_val, inplace=True)\n        print(f\"  • {col}: rempli avec médiane ({median_val})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:50:39.893552Z","iopub.execute_input":"2025-12-14T21:50:39.893824Z","iopub.status.idle":"2025-12-14T21:50:39.898041Z","shell.execute_reply.started":"2025-12-14T21:50:39.893805Z","shell.execute_reply":"2025-12-14T21:50:39.897457Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Encode categorical variables\n\nlabel_encoders = {}\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    \n    # Combine train and test to ensure all categories are seen\n    combined = pd.concat([X[col], X_test[col]]).astype(str)\n    le.fit(combined)\n    \n    X[col] = le.transform(X[col].astype(str))\n    X_test[col] = le.transform(X_test[col].astype(str))\n    \n    label_encoders[col] = le\n    print(f\"  • {col}: {len(le.classes_)} catégories\")\n\n# Final check for any remaining NaN\nX = X.fillna(0)\nX_test = X_test.fillna(0)\n\nprint(f\"  • X train: {X.shape}\")\nprint(f\"  • X test: {X_test.shape}\")\nprint(f\"  • Features: {X.columns.tolist()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:50:40.755002Z","iopub.execute_input":"2025-12-14T21:50:40.755698Z","iopub.status.idle":"2025-12-14T21:50:41.452685Z","shell.execute_reply.started":"2025-12-14T21:50:40.755672Z","shell.execute_reply":"2025-12-14T21:50:41.452085Z"}},"outputs":[{"name":"stdout","text":"  • ID: 117166 catégories\n  • DATOP: 1096 catégories\n  • FLTID: 1912 catégories\n  • DEPSTN: 134 catégories\n  • ARRSTN: 130 catégories\n  • STD: 88709 catégories\n  • STA: 92423 catégories\n  • STATUS: 5 catégories\n  • AC: 70 catégories\n  • X train: (107833, 9)\n  • X test: (9333, 9)\n  • Features: ['ID', 'DATOP', 'FLTID', 'DEPSTN', 'ARRSTN', 'STD', 'STA', 'STATUS', 'AC']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Split data for validation\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(f\"\\n Split:\")\nprint(f\"  • Train: {X_train.shape}\")\nprint(f\"  • Validation: {X_val.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:50:47.110857Z","iopub.execute_input":"2025-12-14T21:50:47.111526Z","iopub.status.idle":"2025-12-14T21:50:47.141811Z","shell.execute_reply.started":"2025-12-14T21:50:47.111501Z","shell.execute_reply":"2025-12-14T21:50:47.141147Z"}},"outputs":[{"name":"stdout","text":"\n Split:\n  • Train: (86266, 9)\n  • Validation: (21567, 9)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"models = {}\npredictions = {}\nrmse_scores = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:50:53.036184Z","iopub.execute_input":"2025-12-14T21:50:53.036755Z","iopub.status.idle":"2025-12-14T21:50:53.040485Z","shell.execute_reply.started":"2025-12-14T21:50:53.036727Z","shell.execute_reply":"2025-12-14T21:50:53.039790Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# LightGBM\nDEF: \n**LightGBM** is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n\n* Faster training speed and higher efficiency.\n* Lower memory usage.\n* Better accuracy.\n* Support of parallel, distributed, and GPU learning.\n* Capable of handling large-scale data.","metadata":{}},{"cell_type":"code","source":"\nprint(\"\\n1️⃣ LightGBM...\")\nlgb_model = lgb.LGBMRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=7,\n    num_leaves=31,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    verbose=-1\n)\nlgb_model.fit(\n    X_train, y_train, \n    eval_set=[(X_val, y_val)],\n    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n)\nlgb_pred_val = lgb_model.predict(X_val)\nlgb_rmse = np.sqrt(mean_squared_error(y_val, lgb_pred_val))\nprint(f\" Validation RMSE: {lgb_rmse:.2f}\")\n\nmodels['LightGBM'] = lgb_model\npredictions['LightGBM'] = lgb_model.predict(X_test)\nrmse_scores['LightGBM'] = lgb_rmse","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:50:57.327916Z","iopub.execute_input":"2025-12-14T21:50:57.328404Z","iopub.status.idle":"2025-12-14T21:51:01.548399Z","shell.execute_reply.started":"2025-12-14T21:50:57.328376Z","shell.execute_reply":"2025-12-14T21:51:01.547774Z"}},"outputs":[{"name":"stdout","text":"\n1️⃣ LightGBM...\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l2: 11390.4\n Validation RMSE: 106.73\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# 2-XGBoost\nIn machine learning, XGBoost is a supervised ensemble learning algorithm. It combines the predictions of multiple \"weak\" models—typically shallow decision trees—to create a single \"strong\" predictive model. \n* **Gradient Boosting**: It builds trees sequentially, where each new tree is specifically designed to correct the errors (residuals) made by all previous trees.\n* **Extreme**: The \"Extreme\" refers to the engineering optimizations that allow it to push the limits of computing power, making it much faster and more scalable than traditional gradient boosting machines (GBM","metadata":{}},{"cell_type":"code","source":"\nprint(\"\\n2️⃣ XGBoost...\")\nxgb_model = xgb.XGBRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=7,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    verbosity=0\n)\nxgb_model.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    early_stopping_rounds=50,\n    verbose=False\n)\nxgb_pred_val = xgb_model.predict(X_val)\nxgb_rmse = np.sqrt(mean_squared_error(y_val, xgb_pred_val))\nprint(f\"   ✓ Validation RMSE: {xgb_rmse:.2f}\")\n\nmodels['XGBoost'] = xgb_model\npredictions['XGBoost'] = xgb_model.predict(X_test)\nrmse_scores['XGBoost'] = xgb_rmse","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:51:09.033281Z","iopub.execute_input":"2025-12-14T21:51:09.033714Z","iopub.status.idle":"2025-12-14T21:51:14.830915Z","shell.execute_reply.started":"2025-12-14T21:51:09.033691Z","shell.execute_reply":"2025-12-14T21:51:14.830270Z"}},"outputs":[{"name":"stdout","text":"\n2️⃣ XGBoost...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"   ✓ Validation RMSE: 105.23\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# 3. Random Forest","metadata":{}},{"cell_type":"code","source":"\nprint(\"\\n3️⃣ Random Forest...\")\nrf_model = RandomForestRegressor(\n    n_estimators=200,\n    max_depth=15,\n    min_samples_split=5,\n    min_samples_leaf=2,\n    random_state=42,\n    n_jobs=-1,\n    verbose=0\n)\nrf_model.fit(X_train, y_train)\nrf_pred_val = rf_model.predict(X_val)\nrf_rmse = np.sqrt(mean_squared_error(y_val, rf_pred_val))\nprint(f\"   ✓ Validation RMSE: {rf_rmse:.2f}\")\n\nmodels['RandomForest'] = rf_model\npredictions['RandomForest'] = rf_model.predict(X_test)\nrmse_scores['RandomForest'] = rf_rmse","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:52:36.732117Z","iopub.execute_input":"2025-12-14T21:52:36.732810Z","iopub.status.idle":"2025-12-14T21:53:04.538305Z","shell.execute_reply.started":"2025-12-14T21:52:36.732786Z","shell.execute_reply":"2025-12-14T21:53:04.537675Z"}},"outputs":[{"name":"stdout","text":"\n3️⃣ Random Forest...\n   ✓ Validation RMSE: 106.06\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# 4. Gradient Boosting","metadata":{}},{"cell_type":"code","source":"print(\"\\n4️⃣ Gradient Boosting...\")\ngb_model = GradientBoostingRegressor(\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=7,\n    subsample=0.8,\n    random_state=42,\n    verbose=0\n)\ngb_model.fit(X_train, y_train)\ngb_pred_val = gb_model.predict(X_val)\ngb_rmse = np.sqrt(mean_squared_error(y_val, gb_pred_val))\nprint(f\"   ✓ Validation RMSE: {gb_rmse:.2f}\")\n\nmodels['GradientBoosting'] = gb_model\npredictions['GradientBoosting'] = gb_model.predict(X_test)\nrmse_scores['GradientBoosting'] = gb_rmse\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:53:16.016545Z","iopub.execute_input":"2025-12-14T21:53:16.017210Z","iopub.status.idle":"2025-12-14T21:55:42.639252Z","shell.execute_reply.started":"2025-12-14T21:53:16.017185Z","shell.execute_reply":"2025-12-14T21:55:42.638561Z"}},"outputs":[{"name":"stdout","text":"\n4️⃣ Gradient Boosting...\n   ✓ Validation RMSE: 105.85\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Ensemble predictions\n#Calculate weights (inverse of RMSE)\ntotal_inv_rmse = sum(1/score for score in rmse_scores.values())\nweights = {model: (1/score)/total_inv_rmse for model, score in rmse_scores.items()}\n\nfor model, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):\n    print(f\"   {model:20s}: {weight:.3f} (RMSE: {rmse_scores[model]:.2f})\")\n\n# Weighted ensemble prediction\nensemble_pred = np.zeros(len(X_test))\nfor model_name, weight in weights.items():\n    ensemble_pred += predictions[model_name] * weight\n\n# Calculate ensemble validation RMSE\nensemble_val_pred = np.zeros(len(X_val))\nfor model_name, weight in weights.items():\n    ensemble_val_pred += models[model_name].predict(X_val) * weight\n\nensemble_rmse = np.sqrt(mean_squared_error(y_val, ensemble_val_pred))\nprint(f\"\\n Validation RMSE: {ensemble_rmse:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T22:03:51.201030Z","iopub.execute_input":"2025-12-14T22:03:51.201311Z","iopub.status.idle":"2025-12-14T22:03:52.830417Z","shell.execute_reply.started":"2025-12-14T22:03:51.201291Z","shell.execute_reply":"2025-12-14T22:03:52.829796Z"}},"outputs":[{"name":"stdout","text":"   XGBoost             : 0.252 (RMSE: 105.23)\n   GradientBoosting    : 0.250 (RMSE: 105.85)\n   RandomForest        : 0.250 (RMSE: 106.06)\n   LightGBM            : 0.248 (RMSE: 106.73)\n\n Validation RMSE: 104.17\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Create submission file\nsubmission = pd.DataFrame({\n    'ID': test['ID'],\n    'target': ensemble_pred.round().astype(int)\n})\n\nsubmission.to_csv('submission.csv', index=False)\n\n# Feature importance from best model\nbest_model_name = min(rmse_scores, key=rmse_scores.get)\nbest_model = models[best_model_name]\n\nif hasattr(best_model, 'feature_importances_'):\n    feature_importance = pd.DataFrame({\n        'feature': X.columns,\n        'importance': best_model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    for idx, row in feature_importance.head(15).iterrows():\n        print(f\"   {row['feature']:30s} {row['importance']:.4f}\")\n\n\nprint(f\" Fichier de soumission: submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T22:04:23.732321Z","iopub.execute_input":"2025-12-14T22:04:23.732854Z","iopub.status.idle":"2025-12-14T22:04:23.780553Z","shell.execute_reply.started":"2025-12-14T22:04:23.732830Z","shell.execute_reply":"2025-12-14T22:04:23.779846Z"}},"outputs":[{"name":"stdout","text":"   STATUS                         0.3731\n   STA                            0.1000\n   FLTID                          0.0914\n   STD                            0.0855\n   DATOP                          0.0783\n   DEPSTN                         0.0721\n   AC                             0.0715\n   ARRSTN                         0.0666\n   ID                             0.0617\n Fichier de soumission: submission.csv\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}